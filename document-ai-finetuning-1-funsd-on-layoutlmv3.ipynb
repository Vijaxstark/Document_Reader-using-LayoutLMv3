{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ABOUT THESE SET OF NOTEBOOKS:\n\nThis set of notebooks is basically a tutorial for myself to instantly use code for my document AI Task, while fine-tuning the model","metadata":{}},{"cell_type":"code","source":"## Requirements\n\n!pip install -qqq transformers\n!pip install -qqq pytorch_lightning\n!pip install -qqq datasets\n!pip install -qqq wandb\n!pip install -qqq evaluate seqeval","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:11:28.303285Z","iopub.execute_input":"2022-12-11T12:11:28.303738Z","iopub.status.idle":"2022-12-11T12:12:25.522015Z","shell.execute_reply.started":"2022-12-11T12:11:28.303659Z","shell.execute_reply":"2022-12-11T12:12:25.520719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Logging into wandb\n\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_api\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:25.524901Z","iopub.execute_input":"2022-12-11T12:12:25.526506Z","iopub.status.idle":"2022-12-11T12:12:27.481272Z","shell.execute_reply.started":"2022-12-11T12:12:25.526465Z","shell.execute_reply":"2022-12-11T12:12:27.480185Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step : 1 Downloading and exploring the dataset a bit","metadata":{}},{"cell_type":"code","source":"## Requirements\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n## Downloading the dataset\nimport datasets\nfrom datasets import load_dataset\n\nimport evaluate\nimport torch.nn.functional as F\n\n## pytorch lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import WandbLogger\n\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:27.483188Z","iopub.execute_input":"2022-12-11T12:12:27.483587Z","iopub.status.idle":"2022-12-11T12:12:38.42483Z","shell.execute_reply.started":"2022-12-11T12:12:27.483534Z","shell.execute_reply":"2022-12-11T12:12:38.423884Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"nielsr/funsd-layoutlmv3\")","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:38.429201Z","iopub.execute_input":"2022-12-11T12:12:38.429758Z","iopub.status.idle":"2022-12-11T12:12:54.085752Z","shell.execute_reply.started":"2022-12-11T12:12:38.42973Z","shell.execute_reply":"2022-12-11T12:12:54.084766Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Taken from here : https://huggingface.co/spaces/jinhybr/OCR-LayoutLM-v3-Document-Parser/blob/main/app.py\n\nlabels = dataset[\"train\"].features[\"ner_tags\"].feature.names\nid2label = {v: k for v, k in enumerate(labels)}","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:54.087457Z","iopub.execute_input":"2022-12-11T12:12:54.088366Z","iopub.status.idle":"2022-12-11T12:12:54.095651Z","shell.execute_reply.started":"2022-12-11T12:12:54.088301Z","shell.execute_reply":"2022-12-11T12:12:54.094702Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Visualizing the bounding boxes\n\ndef plot_visualization(sample : dict):\n\n    from PIL import ImageDraw, ImageFont\n\n    img = sample[\"image\"]\n    bbox = sample[\"bboxes\"]\n    ner_tags = sample[\"ner_tags\"]\n    \n    draw = ImageDraw.Draw(img)\n    font = ImageFont.load_default()\n    \n    for box, predicted_label in zip(bbox, ner_tags):\n\n        ## The bounding box has been rescaled to the range of [0, 1000] considering an image is [1000, 1000]\n        box[0] = int(img.size[0] * box[0] / 1000)\n        box[1] = int(img.size[1] * box[1] / 1000)\n        box[2] = int(img.size[0] * box[2] / 1000)\n        box[3] = int(img.size[1] * box[3] / 1000)\n        \n        draw.rectangle(box, outline = \"violet\")\n        draw.text(\n            (box[0] + 10, box[1] - 10),\n            text=labels[predicted_label],\n            fill=\"green\",\n            font=font,\n        )\n        \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:24:50.669633Z","iopub.execute_input":"2022-12-11T12:24:50.670158Z","iopub.status.idle":"2022-12-11T12:24:50.68606Z","shell.execute_reply.started":"2022-12-11T12:24:50.670118Z","shell.execute_reply":"2022-12-11T12:24:50.685148Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Exploring the dataset\n\nsample = dataset[\"train\"][6]\nannotated_img = plot_visualization(sample)\nannotated_img   ## seems good","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:54.113965Z","iopub.execute_input":"2022-12-11T12:12:54.118743Z","iopub.status.idle":"2022-12-11T12:12:54.208777Z","shell.execute_reply.started":"2022-12-11T12:12:54.11868Z","shell.execute_reply":"2022-12-11T12:12:54.207227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step : 2 Preparing the dataset for modeling\n\n\nLet's understand how are we going to deal with it.\n\n* The entire notebook is depended on measuring the performance of LayoutLMV3 on FUNSD, hence we can consider this as a task of token classification\n* Hence, we would initially load the LayoutLMV3 (not AutoModelForTokenClassification, but just AutoModel, just to see the inner working)\n* And then, what are input values require to it, and then prepare the data accordingly\n* And finally, we would integrate it with PyTorch Lightning for ease of training and testing, that's it\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel\nimport torch.nn as nn\n\nclass LayoutLMV3ForTokenClassification(nn.Module):\n    \n    def __init__(self, num_classes : int = 7):    ## 7 -> 0 to 6 classes\n        super().__init__()\n        \n        self.model = AutoModel.from_pretrained(\"microsoft/layoutlmv3-base\")\n        hidden_dim = self.model.config.hidden_size    ## 768\n        self.cls_layer = nn.Sequential(nn.Linear(in_features = hidden_dim,\n                                                out_features = hidden_dim),\n                                      nn.ReLU(), nn.Linear(in_features = hidden_dim, out_features = num_classes))\n        \n    def forward(self, batch):\n        output = self.model(input_ids=batch[\"input_ids\"],\n                                bbox=batch[\"bbox\"],\n                                attention_mask=batch[\"attention_mask\"],\n                                pixel_values=batch[\"pixel_values\"]).last_hidden_state[:, :512, :]   ## The output is [none, 709, 768], \n                                                                                                    ## not sure how does that come, so I took the first \n                                                                                                    ## 512 tokens\n        \n        output = self.cls_layer(output)\n        \n        return {\"logits\" : output}","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:54.209752Z","iopub.execute_input":"2022-12-11T12:12:54.210075Z","iopub.status.idle":"2022-12-11T12:12:54.22029Z","shell.execute_reply.started":"2022-12-11T12:12:54.210045Z","shell.execute_reply":"2022-12-11T12:12:54.219208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## Printing what the model requires\n\n# model = LayoutLMV3ForTokenClassification()\n# model.model.forward?","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-11T12:12:54.22175Z","iopub.execute_input":"2022-12-11T12:12:54.222773Z","iopub.status.idle":"2022-12-11T12:12:54.233872Z","shell.execute_reply.started":"2022-12-11T12:12:54.222738Z","shell.execute_reply":"2022-12-11T12:12:54.232998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3\n\nfrom datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n\ncolumn_names = dataset[\"train\"].column_names\n\n# we need to define custom features for `set_format` (used later on) to work properly\nfeatures = Features({\n    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n    'input_ids': Sequence(feature=Value(dtype='int64')),\n    'attention_mask': Sequence(Value(dtype='int64')),\n    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n    'labels': Sequence(feature=Value(dtype='int64')),\n})","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:54.23901Z","iopub.execute_input":"2022-12-11T12:12:54.239296Z","iopub.status.idle":"2022-12-11T12:12:54.247428Z","shell.execute_reply.started":"2022-12-11T12:12:54.239273Z","shell.execute_reply":"2022-12-11T12:12:54.246723Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import LayoutLMv3Processor\nprocessor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\",apply_ocr=False)\n\n## This function would map each of the sample to the appropriate format as required by the model\ndef prepare_dataset(sample):\n    \n    ## sample can be a single dict, or a list of dict, depending upon if we don't use batch or use batch\n    if isinstance(sample, dict):\n        img = sample[\"image\"]\n        tokens = sample[\"tokens\"]\n        bbox = sample[\"bboxes\"]\n        ner_tags = sample[\"ner_tags\"]\n        \n        encoding = processor(images = img, text = tokens, boxes = bbox, word_labels = ner_tags, truncation=True, padding=\"max_length\")\n    \n    elif isinstance(sample, datasets.arrow_dataset.Batch):\n        img = sample[\"image\"]\n        tokens = sample[\"tokens\"]\n        bbox = sample[\"bboxes\"]\n        ner_tags = sample[\"ner_tags\"]\n        \n        encoding = processor(images = img, text = tokens, boxes = bbox, word_labels = ner_tags, truncation=True, padding=\"max_length\")\n        \n    else:\n        img = [item[\"image\"] for item in sample]\n        tokens = [item[\"tokens\"] for item in sample]\n        bbox = [item[\"bboxes\"] for item in sample]\n        ner_tags = [item[\"ner_tags\"] for item in sample]\n        \n        encoding = processor(images = img, text = tokens, boxes = bbox, word_labels = ner_tags, truncation=True, padding=\"max_length\")\n        \n    return encoding","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:54.248751Z","iopub.execute_input":"2022-12-11T12:12:54.249493Z","iopub.status.idle":"2022-12-11T12:12:59.220702Z","shell.execute_reply.started":"2022-12-11T12:12:54.24946Z","shell.execute_reply":"2022-12-11T12:12:59.219943Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = dataset[\"train\"].map(\n    prepare_dataset,\n    batched=True,\n    remove_columns=column_names,\n    features=features,\n)\n\neval_dataset = dataset[\"test\"].map(\n    prepare_dataset,\n    batched=True,\n    remove_columns=column_names,\n    features=features,\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:12:59.222095Z","iopub.execute_input":"2022-12-11T12:12:59.222808Z","iopub.status.idle":"2022-12-11T12:13:05.133571Z","shell.execute_reply.started":"2022-12-11T12:12:59.222769Z","shell.execute_reply":"2022-12-11T12:13:05.132668Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset.set_format(type='torch', columns=['pixel_values', 'input_ids', 'attention_mask','bbox', 'labels'])\neval_dataset.set_format(type='torch', columns=['pixel_values', 'input_ids', 'attention_mask','bbox', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.136577Z","iopub.execute_input":"2022-12-11T12:13:05.136857Z","iopub.status.idle":"2022-12-11T12:13:05.144143Z","shell.execute_reply.started":"2022-12-11T12:13:05.136832Z","shell.execute_reply":"2022-12-11T12:13:05.1432Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step : 3 Integrating with wandb and Lightning\n\n\nThis step involves defining a datamodule and lightning object for training the model and logging it to wandb","metadata":{}},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n\n  def __init__(self, batch_size:int = 4):\n    super(DataModule, self).__init__()\n    self.batch_size = batch_size\n\n  def train_dataloader(self):\n    return DataLoader(train_dataset, batch_size = self.batch_size,\n                      shuffle = True)\n    \n  def val_dataloader(self):\n    return DataLoader(eval_dataset, batch_size = self.batch_size,\n                      shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.151096Z","iopub.execute_input":"2022-12-11T12:13:05.151683Z","iopub.status.idle":"2022-12-11T12:13:05.200497Z","shell.execute_reply.started":"2022-12-11T12:13:05.151649Z","shell.execute_reply":"2022-12-11T12:13:05.199377Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n## Sanity checks\n# dl = DataModule()\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# sample = next(iter(dl.train_dataloader()))\n\n# for key in list(sample.keys()):\n#     sample[key] = sample[key].to(device)\n\n# model = LayoutLMV3ForTokenClassification().to(device)\n# output = model(sample)\n# output['logits'].shape","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.203681Z","iopub.execute_input":"2022-12-11T12:13:05.203973Z","iopub.status.idle":"2022-12-11T12:13:05.214959Z","shell.execute_reply.started":"2022-12-11T12:13:05.203948Z","shell.execute_reply":"2022-12-11T12:13:05.213987Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv3/Fine_tune_LayoutLMv3_on_FUNSD_(HuggingFace_Trainer).ipynb\n\n## Would be useful for prediction\ndef get_labels(predictions, references):\n\n    # Transform predictions and references tensors to numpy arrays\n    if predictions.device.type == \"cpu\":\n        y_pred = predictions.detach().clone().numpy()\n        y_true = references.detach().clone().numpy()\n\n    else:\n        y_pred = predictions.detach().cpu().clone().numpy()\n        y_true = references.detach().cpu().clone().numpy()\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [labels[p] for (p, l) in zip(pred, gold_label) if l != -100]\n        for pred, gold_label in zip(y_pred, y_true)\n    ]\n    true_labels = [\n        [labels[l] for (p, l) in zip(pred, gold_label) if l != -100]\n        for pred, gold_label in zip(y_pred, y_true)\n    ]\n    return true_predictions, true_labels","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.216533Z","iopub.execute_input":"2022-12-11T12:13:05.216906Z","iopub.status.idle":"2022-12-11T12:13:05.226014Z","shell.execute_reply.started":"2022-12-11T12:13:05.216837Z","shell.execute_reply":"2022-12-11T12:13:05.225111Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PLModel(pl.LightningModule):\n\n  def __init__(self, lr = 5e-5):\n\n    super(PLModel, self).__init__()\n    self.save_hyperparameters()\n    \n    self.model = LayoutLMV3ForTokenClassification()\n\n    ## Metrics\n    self.train_metric = evaluate.load(\"seqeval\")\n    self.val_metric = evaluate.load(\"seqeval\")\n\n    ## Parameters\n    self.lr = lr\n  \n  def forward(self, batch):\n    return self.model(batch)\n\n  def configure_optimizers(self):\n    return AdamW(self.model.parameters(), lr = self.lr)\n\n  def training_step(self, batch, batch_idx):\n\n    ## Forward Propagatipn\n    outputs = self.forward(batch)\n\n    ## Predictions and adding the metrics\n    predictions = outputs['logits'].argmax(-1)\n    true_predictions, true_labels = get_labels(predictions, batch[\"labels\"])\n    self.train_metric.add_batch(references=true_labels, predictions=true_predictions)\n\n    ## Logging Purpose\n    results = self.train_metric.compute()\n    loss = F.cross_entropy(outputs['logits'].view(-1, 7), batch[\"labels\"].view(-1))\n    \n    self.log(\"train_loss\", loss.item(), prog_bar = True)\n    self.log(\"train_overall_fl\", results[\"overall_f1\"], prog_bar = True)\n    self.log(\"train_overall_recall\", results[\"overall_recall\"], prog_bar = True)\n    self.log(\"train_overall_precision\", results[\"overall_precision\"], prog_bar = True)\n\n    return loss\n\n  def validation_step(self, batch, batch_idx):\n\n    outputs = self.forward(batch)\n    predictions = outputs['logits'].argmax(-1)\n    true_predictions, true_labels = get_labels(predictions, batch[\"labels\"])\n    self.val_metric.add_batch(references=true_labels, predictions=true_predictions)\n\n    ## Logging Purpose\n    results = self.val_metric.compute()\n    loss = F.cross_entropy(outputs['logits'].view(-1, 7), batch[\"labels\"].view(-1))\n    \n    self.log(\"val_loss\", loss.item(), prog_bar = True)\n    self.log(\"val_overall_fl\", results[\"overall_f1\"], prog_bar = True)\n    self.log(\"val_overall_recall\", results[\"overall_recall\"], prog_bar = True)\n    self.log(\"val_overall_precision\", results[\"overall_precision\"], prog_bar = True)\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.227308Z","iopub.execute_input":"2022-12-11T12:13:05.227741Z","iopub.status.idle":"2022-12-11T12:13:05.244475Z","shell.execute_reply.started":"2022-12-11T12:13:05.227706Z","shell.execute_reply":"2022-12-11T12:13:05.241516Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    \n    checkpoint_callback = ModelCheckpoint(\n        dirpath=\"./layoutlmv3/models\", monitor=\"val_loss\", mode=\"min\", filename = 'layoutlmv3_best_ckpt'\n    )\n    \n    wandb.init(project=\"Document AI FUNSD\")\n    wandb_logger = WandbLogger(project=\"Document AI FUNSD\", entity=\"iakarshu\")\n    \n    max_epochs = 50\n    trainer = pl.Trainer(\n        max_epochs = max_epochs,\n        default_root_dir=\"./layoutlmv3/logs\",\n        accelerator=\"auto\", \n        devices=\"auto\",\n        logger=wandb_logger,\n        callbacks=[checkpoint_callback]\n    )\n    \n    pl_model = PLModel()\n    pl_dl = DataModule()\n    \n    trainer.fit(pl_model, pl_dl)\n\n    return pl_model, pl_dl","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.246389Z","iopub.execute_input":"2022-12-11T12:13:05.247386Z","iopub.status.idle":"2022-12-11T12:13:05.261743Z","shell.execute_reply.started":"2022-12-11T12:13:05.24735Z","shell.execute_reply":"2022-12-11T12:13:05.260548Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n  pl_model, pl_dl = main()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:13:05.263611Z","iopub.execute_input":"2022-12-11T12:13:05.264095Z","iopub.status.idle":"2022-12-11T12:14:22.501482Z","shell.execute_reply.started":"2022-12-11T12:13:05.264062Z","shell.execute_reply":"2022-12-11T12:14:22.500284Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step : 4 Evaluation","metadata":{}},{"cell_type":"code","source":"import os\nmodel_path = os.path.join('./layoutlmv3/models', os.listdir('./layoutlmv3/models')[0])\npl_model = pl_model.load_from_checkpoint(model_path)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:14:22.503544Z","iopub.execute_input":"2022-12-11T12:14:22.503933Z","iopub.status.idle":"2022-12-11T12:14:30.759272Z","shell.execute_reply.started":"2022-12-11T12:14:22.503898Z","shell.execute_reply":"2022-12-11T12:14:30.757975Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\neval_metric = evaluate.load(\"seqeval\")\npl_model.eval();\n\nmodel = pl_model.model.to(device)\n\nfor idx, batch in enumerate(tqdm(pl_dl.val_dataloader())):\n    # move batch to device\n    batch = {k:v.to(device) for k,v in batch.items()}\n    with torch.no_grad():\n      outputs = model(batch)\n\n    predictions = outputs['logits'].argmax(-1)\n    true_predictions, true_labels = get_labels(predictions, batch[\"labels\"])\n    eval_metric.add_batch(references=true_labels, predictions=true_predictions)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:14:30.761313Z","iopub.execute_input":"2022-12-11T12:14:30.761693Z","iopub.status.idle":"2022-12-11T12:14:34.171022Z","shell.execute_reply.started":"2022-12-11T12:14:30.761659Z","shell.execute_reply":"2022-12-11T12:14:34.167254Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = eval_metric.compute()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:14:34.172816Z","iopub.execute_input":"2022-12-11T12:14:34.173216Z","iopub.status.idle":"2022-12-11T12:14:34.465325Z","shell.execute_reply.started":"2022-12-11T12:14:34.173157Z","shell.execute_reply":"2022-12-11T12:14:34.464118Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in ['overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']:\n  print_statement = '{0: <30}'.format(str(key) + \" has value:\")\n  print(print_statement, results[key])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:14:34.467125Z","iopub.execute_input":"2022-12-11T12:14:34.467546Z","iopub.status.idle":"2022-12-11T12:14:34.480314Z","shell.execute_reply.started":"2022-12-11T12:14:34.467507Z","shell.execute_reply":"2022-12-11T12:14:34.47923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step : 5 Visualizing the Prediction on test dataset","metadata":{}},{"cell_type":"code","source":"sample = eval_dataset[0]\nfor key in list(sample.keys()):\n    sample[key] = sample[key].unsqueeze(0).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:39.752153Z","iopub.execute_input":"2022-12-11T12:26:39.753125Z","iopub.status.idle":"2022-12-11T12:26:39.763369Z","shell.execute_reply.started":"2022-12-11T12:26:39.753089Z","shell.execute_reply":"2022-12-11T12:26:39.762371Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = model(sample)\npredictions = outputs['logits'].argmax(-1)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:40.074682Z","iopub.execute_input":"2022-12-11T12:26:40.075013Z","iopub.status.idle":"2022-12-11T12:26:40.100199Z","shell.execute_reply.started":"2022-12-11T12:26:40.074984Z","shell.execute_reply":"2022-12-11T12:26:40.099353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pad_token_id = 0\nfor i, j in enumerate(sample[\"input_ids\"][0]):\n    if j == 1:\n        pad_token_id = i\n        break\n        \npredictions = predictions.squeeze(0)[:pad_token_id]\nactual_prediction = [i.item() for i in predictions]\n\nfor key in list(sample.keys()):\n    sample[key] = sample[key].squeeze(0)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:41.524753Z","iopub.execute_input":"2022-12-11T12:26:41.525115Z","iopub.status.idle":"2022-12-11T12:26:41.552606Z","shell.execute_reply.started":"2022-12-11T12:26:41.525084Z","shell.execute_reply":"2022-12-11T12:26:41.551686Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample['ner_tags'] = actual_prediction","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:41.786674Z","iopub.execute_input":"2022-12-11T12:26:41.787274Z","iopub.status.idle":"2022-12-11T12:26:41.800554Z","shell.execute_reply.started":"2022-12-11T12:26:41.787235Z","shell.execute_reply":"2022-12-11T12:26:41.799218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms import ToPILImage\n\nsample['image'] = ToPILImage()(sample.pop('pixel_values')).resize((500, 500))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:42.077777Z","iopub.execute_input":"2022-12-11T12:26:42.078078Z","iopub.status.idle":"2022-12-11T12:26:42.094943Z","shell.execute_reply.started":"2022-12-11T12:26:42.078051Z","shell.execute_reply":"2022-12-11T12:26:42.094074Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample.pop(\"attention_mask\")\nsample['bboxes'] = sample.pop(\"bbox\").tolist()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:42.446533Z","iopub.execute_input":"2022-12-11T12:26:42.446822Z","iopub.status.idle":"2022-12-11T12:26:42.452942Z","shell.execute_reply.started":"2022-12-11T12:26:42.446788Z","shell.execute_reply":"2022-12-11T12:26:42.451796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_visualization(sample)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:26:42.966878Z","iopub.execute_input":"2022-12-11T12:26:42.967211Z","iopub.status.idle":"2022-12-11T12:26:43.017244Z","shell.execute_reply.started":"2022-12-11T12:26:42.967162Z","shell.execute_reply":"2022-12-11T12:26:43.016443Z"},"trusted":true},"outputs":[],"execution_count":null}]}